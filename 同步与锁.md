在并发编程中，我们需要同步和锁来保证程序的正确性。很多概念在学校的时候都有学过。
干了多年程序员反而越来越模糊了。这里整理一下java中的相关的一些内容。

##  synchronized

该关键字应该是java中多线程同步中使用的最多也是最简单的。

* 实现原理

  代码块同步是使用monitorenter和monitorexit指令实现，monitorenter指令是在编译后插入同步代码块的开始位置，而monitorexit插入到方法结束处和异常处。
  本质上是在对象上加互斥锁实现的。

* 效果和注意点
    1. 在不同成员方法上加synchronized，实际上锁的是当前实例对象。
    2. 在静态方法上加synchronized，锁的是当前类的class对象。
    3. 同步块，锁的是synchronized括号里指定的对象。
    4. 因为同步方法其实锁的是对象，在进入一个对象的同步方法的同时，该对象的另一个同步方法
    也会有锁冲突。但是非同步方法不会有锁冲突。

## volatile

如果一个变量被声明为volatile，jvm会保证所有线程看到该变量的值是一致的（通过强制变量的
读写操作都在主内存上进行，而不是在CPU缓存上进行）。volatile提供了
更低成本的实现线程同步的方式，使用它不会引起线程上下文切换和调度。

* 注意点
   volatile不能保证操作的原子性。所以它的适用范围较小。比如：

   ```java
   volatile int count = 0;

   public void inrc(){
               count++;
   }
   ```
   在多线程环境下，并不能保证count的一致。这时候通过在写volatile标量的代码块上
   加上synchronized关键字，能够保证正确性。在上面的inrc()函数加上synchronized即可。

## 可重入锁ReentrantLock
* 可重入锁可以是公平锁（越早等待锁的线程越先获得锁）也可以是非公平的，它提供了两种构造函数。
    ```java
    /**
     * Creates an instance of {@code ReentrantLock}.
     * This is equivalent to using {@code ReentrantLock(false)}.
     */
    public ReentrantLock() {
        sync = new NonfairSync();
    }

    /**
     * Creates an instance of {@code ReentrantLock} with the
     * given fairness policy.
     *
     * @param fair {@code true} if this lock should use a fair ordering policy
     */
    public ReentrantLock(boolean fair) {
        sync = fair ? new FairSync() : new NonfairSync();
    }
    ```
* 阅读ReentrantLock的源码，可以看到可重入锁的实现使用的是sun.misc.Unsafe包下的
compareAndSwapInt函数，这是jvm的CAS指令的封装。所以可重入锁的实现用的是轻量级锁（乐观锁），
在锁冲突不高的情况下性能比synchronized（悲观锁）要高（虽然jvm做了很多的锁优化）。

* 可重入锁可以选择获得锁的线程是否可以被打断，ReentrantLock有3个获得锁的函数：
    1. lock() 如果线程获取不到锁，就一直阻塞等待。
    2. tryLock() 如果能够获得锁，则返回true，否则，返回false。
    3. lockInterruptibly() 与lock()一样，取不到锁会等待，但是可以中断等待。可以用
    线程的interrupt()方法来中断阻塞的线程。

    1，2两个函数比较好理解，lock()方法跟synchronized的语义几乎是一致的。tryLock()提供了一种轮询锁的方式。
    lockInterruptibly()可能稍微有些难理解。需要先理解一下线程的中断机制：

    1. 线程在sleep或者wait、join的时候，可以被打断，这时候调用这个线程的interrupt()
    方法，该线程就会抛出InterruptedException异常。
    2. 如果该线程在运行状态，不会被打断，但是会设置打断标志（不同于线程的stop方法，stop会直接
    中断线程，导致程序可能进入异常的状态，所以一般正常中断线程不使用stop）。

    如果某一线程 A 正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，
    想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，如果用的是lock()或者synchronized，则它不会去理会该中断，
    而是让线程B继续等待，而如果用的是lockInterruptibly()，那么它便会处理中断，让线程B放弃等待，转而去处理其他事情。

    从上面的描述可以看出，可重入锁好像要比synchronized关键字要“更好”，但是其实synchronized
    有个最重要的有点：简单。再大部分场景中，我们是不需要ReentrantLock提供的各种高级功能的，
    复杂度的引入意味着出错率的提高，特别是在多线程编程中，错误往往是很难发现的。所以，除非synchronized
    已经不能胜任你的任务了，不要轻易的选择ReentrantLock。

## JVM对锁的优化
   我们知道，synchronized关键字使用的是悲观锁。对以前版本的JVM来说，这是正确的。但是JVM的开发
   者们，一直再对其进行优化。现在的synchronized，已经不能简单的说是悲观锁实现的了。

   1. 轻量级锁（乐观锁）<br>
   上面提到过，可重入锁其实是乐观锁实现。乐观锁假定每次获取锁都不会产生锁冲突，synchronized为了获得更高的性能，使用了轻量级锁进行
   优化。引入轻量级锁的主要目的是在多没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。
   当线程获取锁时，会在当前线程的栈帧里创建lock record(锁记录变量)，
   让lock record的指针指向锁对象的对象头中的mark word，再让mark word 指向lock record，这就是获取了锁。
   交换通过CAS（compare and swap)指令实现。

   2. 锁自旋 <br>
   如果轻量级锁获取失败，则jvm会将锁膨胀为重量级锁（使用操作系统的互斥量实现）。如果是互斥锁
   那么这个线程会阻塞，等待锁释放后被操作系统唤起。但是在实际场景中，占用锁的线程往往很快执行
   完成并释放锁。操作系统唤醒阻塞的线程的过程中有线程上下文的切换，抢占CPU等开销。而自旋锁的过程
   则是获取锁的线程自旋等待（忙轮询）锁释放，如果占有锁的线程很快释放了锁，该线程就能获得锁并运行，
   省去了线程切换的开销。因为自旋的线程其实一直占用着cpu资源，如果等待的时间过长，等于浪费了cpu资源，
   所以自旋锁会有一个等待时间，如果该时间内一直获取不到锁，那么线程阻塞挂起，等待操作系统唤醒。

   3. 偏向锁 <br>
   如果连续多次的请求锁的操作都是同一个线程执行的（在锁竞争不激烈的场景下大部分都是这种情形），重复的加锁解锁
   过程实际上是多余的操作，这个时候，如果线程持有偏向锁，那么再次获取锁时，可以不进行任何操作。
   如果不同的线程来获取锁，那这个锁就升级为一般的锁。在锁竞争激烈的场景中，偏向锁的效果不佳。

   4. 锁消除 <br>
   顾名思义，锁消除就是消除不必要的锁。锁消除是通过Java中的逃逸分析实现的。
   逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。
   例如：
   ```java
   public StringBuffer craeteStringBuffer(String s1, String s2) {
        StringBuffer sb = new StringBuffer();
        sb.append(s1);
        sb.append(s2);
        return sb;
    }
    ```
    StringBuffer sb是一个方法内部变量，上述代码中直接将sb返回，这样这个StringBuffer有可能被其他方法所改变，
    这样它的作用域就不只是在方法内部，虽然它是一个局部变量，称其逃逸到了方法外部。
    如果一个变量被另外的线程访问，则称为线程逃逸。如果一个变量可以证明是不会逃逸到线程外
    的，那我们可以对它进行一系列性能优化，其中就包括锁消除。

    如果理解了逃逸分析，锁消除的理解就很简单了，不会逃逸到其他线程的对象，说明永远也不会需要同步操作，
    这个时候的一些同步操作就可以“消除”了。
    比如上面的代码，如果改成：
    ```java
    public String craeteStringBuffer(String s1, String s2) {
        StringBuffer sb = new StringBuffer();
        sb.append(s1);
        sb.append(s2);
        return sb.toString();
    }
    ```
    基于逃逸分析，sb的作用域只在函数内部，自然也不可能发生线程逃逸，那么StringBuffer在
    进行append操作的同步操作可以完全被消除，从而提高性能。

   5. 锁粗化<br>
    通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完公共资源后，应该立即释放锁。
    只有这样，等待在这个锁上的其他线程才能尽早的获得资源执行任务。但是，如果对同一个锁不停的进行请求、同步和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。
    比如：
    ```java
    for(int i=0;i<100;i++){
	    synchronized(lock){
	          //do something
	    }
	}
	```
	如果代码变成：
    ```java
    synchronized(lock){
        for(int i=0;i<100;i++){
              //do something
        }
	}
	```
	那么执行效果会好很多。但是如果for循环执行的时间非常久，我们需要给其他线程执行的机会，
	那么，多次加锁也许才是解决方案。JVM会自动对连续加锁进行优化。

## 其他
说了这么多Java的同步方案，其实JVM中具体的实现要复杂的多。追本溯源，我们追求的目标还是高效
的并发，其他语言，如Cpython，因为GIL的存在，线程本身就是串行的。这时候，大家想到的是多进程 + 协程的方式实现高效并发。
在我看来，这种方式也许更为优雅和简单。据说Java以后的并发方案也会朝协程的方向进行！






